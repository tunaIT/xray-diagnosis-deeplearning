# -*- coding: utf-8 -*-
"""VGG19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucfDUp4a7VlNiQHkCRXH7_7oAumB1YaP
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd '/content/gdrive/MyDrive/tieu_luan'

import pandas as pd
import os
from glob import glob
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
# Định nghĩa các hằng số và xử lý dữ liệu
# Định nghĩa các hằng số
LABELS = ['Atelectasis', 'Pneumothorax', 'Effusion', 'Pneumonia', 'Pleural_Thickening']
NUM_CLASSES = len(LABELS)
BATCH_SIZE = 32
NUM_EPOCHS = 10
LEARNING_RATE = 1e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Tải lại các tập dữ liệu từ các tệp CSV
train_df = pd.read_csv('train_data.csv')
val_df = pd.read_csv('val_data.csv')
test_df = pd.read_csv('test_data.csv')
# Định nghĩa các hằng số và xử lý dữ liệu
# Định nghĩa lớp Dataset
class ChestXRayDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        row = self.dataframe.iloc[idx]
        image_path = row['path']
        label = torch.tensor(eval(row['encoded_labels']), dtype=torch.float32)

        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return image, label

# Định nghĩa các phép biến đổi dữ liệu với augmentation
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Tạo datasets và dataloaders
train_dataset = ChestXRayDataset(train_df, transform=transform)
val_dataset = ChestXRayDataset(val_df, transform=transform)
test_dataset = ChestXRayDataset(test_df, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Định nghĩa mô hình với VGG19
class MultiLabelVGG19(nn.Module):
    def __init__(self, num_classes):
        super(MultiLabelVGG19, self).__init__()
        self.base_model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)
        # Loại bỏ các lớp fully connected (classifier) của VGG19
        self.base_model = nn.Sequential(*list(self.base_model.features.children()))

        # Lớp chuyển tiếp để thay đổi số kênh đầu ra
        self.transition_layer = nn.Sequential(
            nn.Conv2d(512, 1024, kernel_size=1),
            nn.Dropout(p=0.5)  # Dropout để giảm overfitting
        )

        self.global_pooling = nn.AdaptiveAvgPool2d((1, 1))
        self.prediction_layer = nn.Linear(1024, num_classes)

    def forward(self, x):
        x = self.base_model(x)
        x = self.transition_layer(x)
        x = self.global_pooling(x)
        x = x.view(x.size(0), -1)
        x = self.prediction_layer(x)
        return x

# Tính toán trọng số dương và âm cho các lớp
import torch
import numpy as np

# Assuming 'encoded_labels' column contains strings like '[0, 1, 0, 0, 1]'
all_labels_list = train_df['encoded_labels'].apply(lambda x: eval(x)).tolist() # Convert strings to lists
all_labels = torch.tensor(np.vstack(all_labels_list), dtype=torch.float32) # Stack and convert to tensor
pos_weight = all_labels.sum(dim=0) + 1e-7
neg_weight = all_labels.size(0) - pos_weight + 1e-7

# Tính toán trọng số toàn cục
beta_p = (pos_weight + neg_weight) / pos_weight
beta_n = (pos_weight + neg_weight) / neg_weight

# Sử dụng BCEWithLogitsLoss với trọng số
criterion = nn.BCEWithLogitsLoss(pos_weight=beta_p.to(DEVICE))

# Khởi tạo mô hình, bộ tối ưu và bộ điều chỉnh learning rate
model = MultiLabelVGG19(NUM_CLASSES).to(DEVICE)
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1)

# Vòng lặp huấn luyện và validation với early stopping
best_val_loss = float('inf')
patience_counter = 0
patience_threshold = 3

for epoch in range(NUM_EPOCHS):
    model.train()
    train_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    val_loss = 0
    model.eval()
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    train_loss /= len(train_loader)
    val_loss /= len(val_loader)
    print(f"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

    # Kiểm tra early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        torch.save(model.state_dict(), 'best_model_vgg.pth')  # Lưu mô hình tốt nhất
    else:
        patience_counter += 1
        if patience_counter >= patience_threshold:
            print("Early stopping triggered.")
            break

    scheduler.step(val_loss)

# Đánh giá trên tập kiểm tra
model.load_state_dict(torch.load('best_model_vgg.pth'))  # Tải mô hình tốt nhất
model.eval()
all_labels, all_predictions = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        outputs = model(images)
        all_labels.append(labels.cpu().numpy())
        all_predictions.append(outputs.cpu().numpy())

# Xử lý và lưu kết quả
all_labels = np.vstack(all_labels)
all_predictions = np.vstack(all_predictions)
np.savez('results_vgg.npz', labels=all_labels, predictions=all_predictions)

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from prettytable import PrettyTable

# Load results
results = np.load('results_vgg.npz')
all_labels = results['labels']
all_predictions = results['predictions']

LABELS = ['Atelectasis', 'Pneumothorax', 'Effusion', 'Pneumonia', 'Pleural_Thickening']

# Bảng hiển thị các chỉ số với ngưỡng cố định là 0.5
print("\nMetrics: Accuracy, Precision, Recall, F1-score, AUC-ROC")
metrics_table_fixed = PrettyTable()
metrics_table_fixed.field_names = ["Disease Label", "Accuracy", "Precision", "Recall", "F1-score", "AUC-ROC"]

auc_scores_fixed = []
for i, label in enumerate(LABELS):
    true_labels = all_labels[:, i]
    pred_labels = (all_predictions[:, i] > 0.5).astype(int)  # Sử dụng ngưỡng cố định là 0.5

    accuracy = accuracy_score(true_labels, pred_labels)
    precision = precision_score(true_labels, pred_labels, zero_division=0)
    recall = recall_score(true_labels, pred_labels, zero_division=0)
    f1 = f1_score(true_labels, pred_labels, zero_division=0)

    # Tính AUC-ROC
    try:
        auc_roc = roc_auc_score(true_labels, pred_labels)
        auc_scores_fixed.append(auc_roc)
        auc_value = f"{auc_roc:.4f}"
    except ValueError:
        auc_scores_fixed.append(float('nan'))
        auc_value = "N/A"

    metrics_table_fixed.add_row([label, f"{accuracy:.4f}", f"{precision:.4f}", f"{recall:.4f}", f"{f1:.4f}", auc_value])

print(metrics_table_fixed)

# Tính Macro Averages với ngưỡng 0.5
accuracy_macro_fixed = np.mean([
    accuracy_score(all_labels[:, i], (all_predictions[:, i] > 0.5).astype(int))
    for i in range(len(LABELS))
])
precision_macro_fixed = np.mean([
    precision_score(all_labels[:, i], (all_predictions[:, i] > 0.5).astype(int), zero_division=0)
    for i in range(len(LABELS))
])
recall_macro_fixed = np.mean([
    recall_score(all_labels[:, i], (all_predictions[:, i] > 0.5).astype(int), zero_division=0)
    for i in range(len(LABELS))
])
f1_macro_fixed = np.mean([
    f1_score(all_labels[:, i], (all_predictions[:, i] > 0.5).astype(int), zero_division=0)
    for i in range(len(LABELS))
])
auc_macro_fixed = np.nanmean(auc_scores_fixed)  # Bỏ qua giá trị NaN

# In kết quả Macro Average
metrics_table_macro_fixed = PrettyTable()
metrics_table_macro_fixed.field_names = ["Metric", "Macro Average"]
metrics_table_macro_fixed.add_row(["Accuracy", f"{accuracy_macro_fixed:.4f}"])
metrics_table_macro_fixed.add_row(["Precision", f"{precision_macro_fixed:.4f}"])
metrics_table_macro_fixed.add_row(["Recall", f"{recall_macro_fixed:.4f}"])
metrics_table_macro_fixed.add_row(["F1-Score", f"{f1_macro_fixed:.4f}"])
metrics_table_macro_fixed.add_row(["AUC-ROC", f"{auc_macro_fixed:.4f}"])

print("\nMacro Average Metrics")
print(metrics_table_macro_fixed)